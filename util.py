import os 
import random
from tqdm import tqdm 
from music21 import *

random.seed(1)

def get_parsed_notes(music21_notes):
  '''
  Takes in the notes and chords that are music21
  classes as a 2D list (collection of notes for each song
  in the training data).

  Returns
  -------
  notes: list of Note and Chord representations that are hashable
  '''
  notes = []
  for note_group in tqdm(music21_notes, desc="Extracting Notes and Chords..."):
    notes.append([])
    for sound in note_group:
      if isinstance(sound, note.Note):
        notes[-1].append(str(sound.pitch))
      elif isinstance(sound, chord.Chord):
        notes[-1].append('.'.join(str(n) for n in sound.normalOrder))

  # [Jens]: I don't think we need normalization here, since all
  # of our features are already on the same scale.

  return notes

def get_music21_notes(songs, voice='soprano'):
  '''
  Takes in a list of songs (e.g. "Bach") and parses each one.
  Currently, we take the first 'part' of the song and return
  all its notes and chords.

  Returns
  -------
  notes_to_parse: list of Music21 Notes and Chords
  '''
  notes_to_parse = []
  for song in tqdm(songs, desc="Parsing Songs..."):
    parsed_song = corpus.parse(song)
    # We probably want to make this more flexible so
    # it can take in the part we want?
    part = parsed_song.parts.stream()[voice]
    notes_to_parse.append([note for note in part.flat.notes])

  return notes_to_parse

def get_music_data(datasetNum, voice='soprano'):
  '''
  Load the Bach corpus and split the data into training and test.
  '''
  bach_songs = corpus.getComposer('bach')
  song_list = []
  tqdm_iter = tqdm(total = datasetNum, desc="Getting Music Data...", initial=1)
  trained_songs = 1
  idx = 0
  while trained_songs < datasetNum:
    
    song = None
    if(os.name == 'posix'):
      song = 'bach/' + '.'.join(str(bach_songs[idx]).split('/')[-1].split('.')[:-1])
    else:
      song = 'bach/' + '.'.join(str(bach_songs[idx]).split('\\')[-1].split('.')[:-1])
    
    # Check if Soprano voice exits
    parsed_song = corpus.parse(song)

    # Hack to test if the song has a soprano voice
    try:
      part = parsed_song.parts.stream()[voice]
      song_list.append(song)
      trained_songs += 1
      tqdm_iter.update(1)
    except:
      pass
    idx += 1
  tqdm_iter.close()

  # Randomize the songs before making training and test split
  random.shuffle(song_list)

  index_split = int(datasetNum * .8)
  return (song_list[:index_split], song_list[index_split:])

def play_music(predicted):
  '''
  Convert the predicted output into a midi file
  Literal copy of https://github.com/Skuldur/Classical-Piano-Composer/blob/master/lstm.py
  We're probably going to want to adjust this one to have different offsets etc.
  '''
  offset = 0
  output_notes = []

  # create note and chord objects based on the values generated by the model
  for pattern in predicted:
      # pattern is a chord
      if ('.' in pattern) or pattern.isdigit():
          notes_in_chord = pattern.split('.')
          notes = []
          for current_note in notes_in_chord:
              new_note = note.Note(int(current_note))
              new_note.storedInstrument = instrument.Piano()
              notes.append(new_note)
          new_chord = chord.Chord(notes)
          new_chord.offset = offset
          output_notes.append(new_chord)
      # pattern is a note
      else:
          new_note = note.Note(pattern)
          new_note.offset = offset
          new_note.storedInstrument = instrument.Piano()
          output_notes.append(new_note)

      # increase offset each iteration so that notes do not stack
      offset += 0.5

  midi_stream = stream.Stream(output_notes)
  midi_stream.show()

  